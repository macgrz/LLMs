{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from models import GPTModel\n",
    "\n",
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,\n",
    "    \"context_lenght\": 256,\n",
    "    \"emb_dim\": 768,\n",
    "    \"n_heads\": 12,\n",
    "    \"n_layers\": 12,\n",
    "    \"drop_rate\": 0.1,\n",
    "    \"qkv_bias\": False\n",
    "}\n",
    "\n",
    "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]    # crop current context if it exceeds the supported size\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "\n",
    "        logits = logits[:, -1, :]   # focus only on last time step so that (batch, n_tokens, vocab_size) becomes (batch, vocab_size)\n",
    "        probas = torch.softmax(logits, dim=-1)\n",
    "        idx_next = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "        idx = torch.cat((idx, idx_next), dim=1)\n",
    "\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Prepare functions for generating text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "start_context = \"Every effort moves you\"\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval()\n",
    "\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0) # add the batch dimensionality\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0)\n",
    "    decoded = tokenizer.decode(flat.tolist())\n",
    "    return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Every effort moves you rentingãƒŽJohnIncvertSw440 Lead nylon>>>>'"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(start_context, tokenizer),\n",
    "    max_new_tokens=10,\n",
    "    context_size=GPT_CONFIG_124M[\"context_lenght\"]\n",
    ")\n",
    "\n",
    "token_ids_to_text(token_ids, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.tensor([[16833, 3626, 6100],     # Every effort moves\n",
    "                       [40, 1107, 588]])        # I really like\n",
    "\n",
    "targets = torch.tensor([[3626, 6100, 345],      # effort moves you\n",
    "                        [1107, 588, 11311]])    # really like chocolate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 50257])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    logits = model(inputs)\n",
    "probas = torch.softmax(logits, dim=-1)\n",
    "probas.shape\n",
    "# 2,    - batches\n",
    "# 3,    - tokens\n",
    "# 50257 - embedding dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0002)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(probas[0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0002)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probas[0][2][44376]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[16657],\n",
       "         [16031],\n",
       "         [44376]],\n",
       "\n",
       "        [[49906],\n",
       "         [29669],\n",
       "         [ 6972]]])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_ids = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "token_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7.2671e-05, 3.1283e-05, 1.2676e-05])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets[0]\n",
    "probas[0, [0,1,2], targets[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target batch 1:  effort moves you     -> tensor([3626, 6100,  345])    -> tensor([7.2671e-05, 3.1283e-05, 1.2676e-05])\n",
      "Output batch 1:  Armed saves inaction -> tensor([16657, 16031, 44376]) -> tensor([0.0002, 0.0002, 0.0002])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Target batch 1: {token_ids_to_text(targets[0], tokenizer)}     -> {targets[0]}    -> {probas[0, [0,1,2], targets[0]]}\")\n",
    "print(f\"Output batch 1: {token_ids_to_text(token_ids[0].flatten(), tokenizer)} -> {token_ids[0].flatten()} -> {probas[0, [0,1,2], token_ids[0].flatten()]}\")\n",
    "target_probas_1 = probas[0, [0,1,2], targets[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target batch 2:  really like chocolate    -> tensor([ 1107,   588, 11311]) -> tensor([1.0426e-05, 5.2505e-05, 5.1900e-06])\n",
      "Output batch 2:  pressuring empoweredowed -> tensor([49906, 29669,  6972]) -> tensor([0.0002, 0.0002, 0.0002])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Target batch 2: {token_ids_to_text(targets[1], tokenizer)}    -> {targets[1]} -> {probas[1, [0,1,2], targets[1]]}\")\n",
    "print(f\"Output batch 2: {token_ids_to_text(token_ids[1].flatten(), tokenizer)} -> {token_ids[1].flatten()} -> {probas[1, [0,1,2], token_ids[1].flatten()]}\")\n",
    "target_probas_2 = probas[1, [0,1,2], targets[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.8436e-05, 2.6831e-05, 1.2676e-05])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probas[\n",
    "    0,          # batch number\n",
    "    [0, 1, 2],  # for all 3 token embeddings \n",
    "    345         # get the one with id 345\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -9.5296, -10.3724, -11.2758, -11.4712,  -9.8546, -12.1688])\n",
      "tensor(-10.7787)\n",
      "tensor(10.7787)\n"
     ]
    }
   ],
   "source": [
    "log_probas = torch.log(torch.cat((target_probas_1, target_probas_2)))   # log probability\n",
    "print(log_probas)\n",
    "avg_log_probas = torch.mean(log_probas)                                 # average log probability\n",
    "print(avg_log_probas)\n",
    "neg_avg_log_probas = -avg_log_probas                                    # negative average log probability == cross entropy loss\n",
    "print(neg_avg_log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits shape: torch.Size([2, 3, 50257])\n",
      "Targets shape: torch.Size([2, 3])\n",
      "Logits shape: torch.Size([6, 50257])\n",
      "Targets shape: torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "# In pytorch:\n",
    "\n",
    "print(f\"Logits shape: {logits.shape}\")\n",
    "print(f\"Targets shape: {targets.shape}\")\n",
    "\n",
    "\n",
    "logits = logits.flatten(0,1)            # needs to flatten so they have common dimension\n",
    "targets = targets.flatten(0,1)\n",
    "\n",
    "print(f\"Logits shape: {logits.shape}\")\n",
    "print(f\"Targets shape: {targets.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(10.7787)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_entropy_loss = torch.nn.functional.cross_entropy(logits, targets)\n",
    "cross_entropy_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(47989.2031)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perplexity = torch.exp(cross_entropy_loss)\n",
    "perplexity  # model was not sure which token to pick from about 47,989 tokens in vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of characters: 20479\n",
      "Total number of tokens: 5145\n"
     ]
    }
   ],
   "source": [
    "file_path = \"the-verdict.txt\"\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    text_data = f.read()\n",
    "\n",
    "total_characters = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "\n",
    "print(f\"Total number of characters: {total_characters}\")\n",
    "print(f\"Total number of tokens: {total_tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the text into training and validation sets,\n",
    "# tokenize text,\n",
    "# divide tokenized text into chunks,\n",
    "# shuffle the rows in dataset\n",
    "\n",
    "train_ratio = 0.9\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloader import create_dataloader_v1\n",
    "\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size=2,\n",
    "    max_lenght=GPT_CONFIG_124M[\"context_lenght\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_lenght\"],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "val_loader = create_dataloader_v1(\n",
    "    val_data,\n",
    "    batch_size=2,\n",
    "    max_lenght=GPT_CONFIG_124M[\"context_lenght\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_lenght\"],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "Training batch 1: (torch.Size([2, 256]), torch.Size([2, 256]))\n",
      "Training batch 2: (torch.Size([2, 256]), torch.Size([2, 256]))\n",
      "Training batch 3: (torch.Size([2, 256]), torch.Size([2, 256]))\n",
      "Training batch 4: (torch.Size([2, 256]), torch.Size([2, 256]))\n",
      "Training batch 5: (torch.Size([2, 256]), torch.Size([2, 256]))\n",
      "Training batch 6: (torch.Size([2, 256]), torch.Size([2, 256]))\n",
      "Training batch 7: (torch.Size([2, 256]), torch.Size([2, 256]))\n",
      "Training batch 8: (torch.Size([2, 256]), torch.Size([2, 256]))\n",
      "Training batch 9: (torch.Size([2, 256]), torch.Size([2, 256]))\n",
      "Val loader:\n",
      "Val batch 1: (torch.Size([2, 256]), torch.Size([2, 256]))\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for i, (x, y) in enumerate(train_loader, start=1):\n",
    "    print(f\"Training batch {i}: {x.shape, y.shape}\")\n",
    "\n",
    "print(\"Val loader:\")\n",
    "for i, (x, y) in enumerate(val_loader, start=1):\n",
    "    print(f\"Val batch {i}: {x.shape, y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch = input_batch.to(device)    # this allows to use GPU\n",
    "    target_batch = target_batch.to(device)\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(logits.flatten(0,1), target_batch.flatten())\n",
    "    return loss\n",
    "\n",
    "\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)  # iterate over all batches if num_batches is not specified\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))    # reduce number of batches to match total number of batches in data loader \n",
    "                                                            # if num_batches exceeds the number of batches in data loader\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 10.986968040466309\n",
      "Validation loss: 10.978693962097168\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader, model, device)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device)\n",
    "\n",
    "print(f\"Training loss: {train_loss}\")\n",
    "print(f\"Validation loss: {val_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
