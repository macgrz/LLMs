{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from models import GPTModel\n",
    "\n",
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,\n",
    "    \"context_lenght\": 256,\n",
    "    \"emb_dim\": 768,\n",
    "    \"n_heads\": 12,\n",
    "    \"n_layers\": 12,\n",
    "    \"drop_rate\": 0.1,\n",
    "    \"qkv_bias\": False\n",
    "}\n",
    "\n",
    "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]    # crop current context if it exceeds the supported size\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "\n",
    "        logits = logits[:, -1, :]   # focus only on last time step so that (batch, n_tokens, vocab_size) becomes (batch, vocab_size)\n",
    "        probas = torch.softmax(logits, dim=-1)\n",
    "        idx_next = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "        idx = torch.cat((idx, idx_next), dim=1)\n",
    "\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Prepare functions for generating text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "start_context = \"Every effort moves you\"\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval()\n",
    "\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0) # add the batch dimensionality\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0)\n",
    "    decoded = tokenizer.decode(flat.tolist())\n",
    "    return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Every effort moves you rentingãƒŽJohnIncvertSw440 Lead nylon>>>>'"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(start_context, tokenizer),\n",
    "    max_new_tokens=10,\n",
    "    context_size=GPT_CONFIG_124M[\"context_lenght\"]\n",
    ")\n",
    "\n",
    "token_ids_to_text(token_ids, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.tensor([[16833, 3626, 6100],     # Every effort moves\n",
    "                       [40, 1107, 588]])        # I really like\n",
    "\n",
    "targets = torch.tensor([[3626, 6100, 345],      # effort moves you\n",
    "                        [1107, 588, 11311]])    # really like chocolate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 50257])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    logits = model(inputs)\n",
    "probas = torch.softmax(logits, dim=-1)\n",
    "probas.shape\n",
    "# 2,    - batches\n",
    "# 3,    - tokens\n",
    "# 50257 - embedding dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0002)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(probas[0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0002)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probas[0][2][44376]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[16657],\n",
       "         [16031],\n",
       "         [44376]],\n",
       "\n",
       "        [[49906],\n",
       "         [29669],\n",
       "         [ 6972]]])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_ids = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "token_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7.2671e-05, 3.1283e-05, 1.2676e-05])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets[0]\n",
    "probas[0, [0,1,2], targets[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target batch 1:  effort moves you     -> tensor([3626, 6100,  345])    -> tensor([7.2671e-05, 3.1283e-05, 1.2676e-05])\n",
      "Output batch 1:  Armed saves inaction -> tensor([16657, 16031, 44376]) -> tensor([0.0002, 0.0002, 0.0002])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Target batch 1: {token_ids_to_text(targets[0], tokenizer)}     -> {targets[0]}    -> {probas[0, [0,1,2], targets[0]]}\")\n",
    "print(f\"Output batch 1: {token_ids_to_text(token_ids[0].flatten(), tokenizer)} -> {token_ids[0].flatten()} -> {probas[0, [0,1,2], token_ids[0].flatten()]}\")\n",
    "target_probas_1 = probas[0, [0,1,2], targets[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target batch 2:  really like chocolate    -> tensor([ 1107,   588, 11311]) -> tensor([1.0426e-05, 5.2505e-05, 5.1900e-06])\n",
      "Output batch 2:  pressuring empoweredowed -> tensor([49906, 29669,  6972]) -> tensor([0.0002, 0.0002, 0.0002])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Target batch 2: {token_ids_to_text(targets[1], tokenizer)}    -> {targets[1]} -> {probas[1, [0,1,2], targets[1]]}\")\n",
    "print(f\"Output batch 2: {token_ids_to_text(token_ids[1].flatten(), tokenizer)} -> {token_ids[1].flatten()} -> {probas[1, [0,1,2], token_ids[1].flatten()]}\")\n",
    "target_probas_2 = probas[1, [0,1,2], targets[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.8436e-05, 2.6831e-05, 1.2676e-05])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probas[\n",
    "    0,          # batch number\n",
    "    [0, 1, 2],  # for all 3 token embeddings \n",
    "    345         # get the one with id 345\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -9.5296, -10.3724, -11.2758, -11.4712,  -9.8546, -12.1688])\n",
      "tensor(-10.7787)\n",
      "tensor(10.7787)\n"
     ]
    }
   ],
   "source": [
    "log_probas = torch.log(torch.cat((target_probas_1, target_probas_2)))   # log probability\n",
    "print(log_probas)\n",
    "avg_log_probas = torch.mean(log_probas)                                 # average log probability\n",
    "print(avg_log_probas)\n",
    "neg_avg_log_probas = -avg_log_probas                                    # negative average log probability == cross entropy loss\n",
    "print(neg_avg_log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits shape: torch.Size([2, 3, 50257])\n",
      "Targets shape: torch.Size([2, 3])\n",
      "Logits shape: torch.Size([6, 50257])\n",
      "Targets shape: torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "# In pytorch:\n",
    "\n",
    "print(f\"Logits shape: {logits.shape}\")\n",
    "print(f\"Targets shape: {targets.shape}\")\n",
    "\n",
    "\n",
    "logits = logits.flatten(0,1)            # needs to flatten so they have common dimension\n",
    "targets = targets.flatten(0,1)\n",
    "\n",
    "print(f\"Logits shape: {logits.shape}\")\n",
    "print(f\"Targets shape: {targets.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(10.7787)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_entropy_loss = torch.nn.functional.cross_entropy(logits, targets)\n",
    "cross_entropy_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(47989.2031)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perplexity = torch.exp(cross_entropy_loss)\n",
    "perplexity  # model was not sure which token to pick from about 47,989 tokens in vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
