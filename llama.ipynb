{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama-stack in /home/mgrzelczyk/.pyenv/versions/3.9.13/envs/llms_venv/lib/python3.9/site-packages (0.0.1a5)\n",
      "Requirement already satisfied: sniffio in /home/mgrzelczyk/.pyenv/versions/3.9.13/envs/llms_venv/lib/python3.9/site-packages (from llama-stack) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /home/mgrzelczyk/.pyenv/versions/3.9.13/envs/llms_venv/lib/python3.9/site-packages (from llama-stack) (4.12.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/mgrzelczyk/.pyenv/versions/3.9.13/envs/llms_venv/lib/python3.9/site-packages (from llama-stack) (4.7.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /home/mgrzelczyk/.pyenv/versions/3.9.13/envs/llms_venv/lib/python3.9/site-packages (from llama-stack) (2.10.4)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/mgrzelczyk/.pyenv/versions/3.9.13/envs/llms_venv/lib/python3.9/site-packages (from llama-stack) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/mgrzelczyk/.pyenv/versions/3.9.13/envs/llms_venv/lib/python3.9/site-packages (from llama-stack) (0.28.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/mgrzelczyk/.pyenv/versions/3.9.13/envs/llms_venv/lib/python3.9/site-packages (from anyio<5,>=3.5.0->llama-stack) (1.2.2)\n",
      "Requirement already satisfied: idna>=2.8 in /home/mgrzelczyk/.pyenv/versions/3.9.13/envs/llms_venv/lib/python3.9/site-packages (from anyio<5,>=3.5.0->llama-stack) (3.10)\n",
      "Requirement already satisfied: certifi in /home/mgrzelczyk/.pyenv/versions/3.9.13/envs/llms_venv/lib/python3.9/site-packages (from httpx<1,>=0.23.0->llama-stack) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /home/mgrzelczyk/.pyenv/versions/3.9.13/envs/llms_venv/lib/python3.9/site-packages (from httpx<1,>=0.23.0->llama-stack) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/mgrzelczyk/.pyenv/versions/3.9.13/envs/llms_venv/lib/python3.9/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->llama-stack) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/mgrzelczyk/.pyenv/versions/3.9.13/envs/llms_venv/lib/python3.9/site-packages (from pydantic<3,>=1.9.0->llama-stack) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /home/mgrzelczyk/.pyenv/versions/3.9.13/envs/llms_venv/lib/python3.9/site-packages (from pydantic<3,>=1.9.0->llama-stack) (2.27.2)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 24.3.1 is available.\n",
      "You should consider upgrading via the '/home/mgrzelczyk/.pyenv/versions/3.9.13/envs/llms_venv/bin/python3.9 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install llama-stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: line 1: llama: command not found\n"
     ]
    }
   ],
   "source": [
    "!llama model list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import llama_stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['APIConnectionError', 'APIError', 'APIResponse', 'APIResponseValidationError', 'APIStatusError', 'APITimeoutError', 'AsyncAPIResponse', 'AsyncClient', 'AsyncLlamaStack', 'AsyncStream', 'AuthenticationError', 'BadRequestError', 'BaseModel', 'Client', 'ConflictError', 'DEFAULT_CONNECTION_LIMITS', 'DEFAULT_MAX_RETRIES', 'DEFAULT_TIMEOUT', 'DefaultAsyncHttpxClient', 'DefaultHttpxClient', 'ENVIRONMENTS', 'InternalServerError', 'LlamaStack', 'LlamaStackError', 'NOT_GIVEN', 'NoneType', 'NotFoundError', 'NotGiven', 'PermissionDeniedError', 'ProxiesTypes', 'RateLimitError', 'RequestOptions', 'Stream', 'Timeout', 'Transport', 'UnprocessableEntityError', '__all__', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__locals', '__name', '__name__', '__package__', '__path__', '__spec__', '__title__', '__version__', '_base_client', '_client', '_compat', '_constants', '_exceptions', '_files', '_models', '_qs', '_resource', '_response', '_setup_logging', '_streaming', '_types', '_utils', '_version', 'file_from_path', 'resources', 'types']\n"
     ]
    }
   ],
   "source": [
    "print(dir(llama_stack))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
